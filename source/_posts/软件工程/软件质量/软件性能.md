---
title: 软件性能
date: 2021-03-23 21:47:22
summary: 本文浅谈软件性能的相关内容。
mathjax: true
tags:
- 软件质量
- 软件工程
categories:
- 软件工程
---

# 程序复杂度

需要先明确大$O$表示法，即$O(f(n))$。
这里的$O$是order的意思，意为大约，而$f(n)$代表函数规模。

大$O$是描述函数性能等价的一种简写，通过这种表示法我们能知道函数的执行步骤数量与输入规模之间的关系。

但是，大$O$并不是说范围是多少就执行到什么范围，尽管往往如此。

大$O$描述的是一个函数数量级的渐进上界。
关于这个上界，学过高等数学的我们都知道，其实并不一定是“紧卡”的，即一个算出来$n^{2}$复杂度的函数的复杂度也可以表示为$O(n^{3})$，这是没有问题的。
当然，大$O$表示中的$f(n)$越接近实际就越好，毕竟一个递归的斐波那契实现表示为$O((\frac{5}{3})^{n})$总是要比$O(2^{n})$精确一些的。

另外，大$O$表示法强调的是数量级，比如$2^{n}$，比如$n^{2}$，比如$\log{n}$，写成$O(5n^{2}+3)$没意义。

对于OJ算法题，${10}^{3}\sim{{10}^{4}}$数据量可以采用$O(n^2)$算法，${10}^{5}$数据量可以采用$O(n\log{n})$算法，${10}^{5}$数据量不一定能采用$O(n\log{n})$算法一般是$O(n)$算法，${10}^{7}$数据量考虑$O(n)$算法。

推荐阅读：[算法复杂度](https://blankspace.blog.csdn.net/article/details/101903721)

# 软件设计与性能

设计阶段，产品的性能(Performance)往往得不到重视，直到遇到性能测试才暴露出诸多性能问题，这是不好的。
学过软件测试后我们都知道，随着开发的推进，修复Bug的代价越来越大。同理，改善产品性能的代价也原来越大。
出众的性能和过硬的质量都来自于可靠的设计，而在开发过程中临时考虑性能或质量则是困难的。

有人说，之前人工智能搞不起来就是因为硬件支持的不够，现在硬件不值钱，堆硬件可以弥补性能。
有一说一确实有点道理，但这并不是忽略性能问题的借口，性能的优化不能只依赖于后期的性能调优或大规模的重构。

尽量不要等到运行起来以后才去尝试大幅改进性能问题，性能问题应该在设计阶段就得到重视，好的算法应该在设计阶段被提出并得到实现。
至于性能优化，那也是必须要做的，只不过不是这里要讨论的话题。

# JVM-G1调优

G1调优总结：
- 参数G1HeapRegionSize指定堆分区大小。分区大小可以指定，也可以不指定；不指定时，由内存管理器启发式推断分区大小。
- 参数xms/xmx指定堆空间的最小值/最大值。一定要正确设置xms/xmx，否则将使用默认配置，将影响分区大小推断。
- 在以前的内存管理器中（非G1），为了防止新生代因为内存不断地重新分配导致性能变低，通常设置Xmn或者NewRatio。但是G1中不要设置MaxNewSize、NewSize、Xmn和NewRatio。原因有两个，第一G1对内存的管理不是连续的，所以即使重新分配一个堆分区代价也不高，第二也是最重要的，G1的目标满足垃圾收集停顿，这需要G1根据停顿时间动态调整收集的分区，如果设置了固定的分区数，即G1不能调整新生代的大小，那么G1可能不能满足停顿时间的要求。具体情况本书后续还会继续讨论。
- 参数GCTimeRatio指的是GC与应用程序之间的时间占比，默认值为9，表示GC与应用程序时间占比为10%。增大该值将减少GC占用的时间，带来的后果就是动态扩展内存更容易发生；在很多情况下10%已经很大，例如可以将该值设置为19，则表示GC时间不超过5%。
- 根据业务请求变化的情况，设置合适的扩展G1ExpandByPercentOfAvailable速率，保持效率。
- JVM在对新生代内存分配管理时，还有一个参数就是保留内存G1ReservePercent（默认值是10），即在初始化，或者内存扩展/收缩的时候会计算更新有多少个分区是保留的，在新生代分区初始化的时候，在空闲列表中保留一定比例的分区不使用，那么在对象晋升的时候就可以使用了，所以能有效地减小晋升失败的概率。这个值最大不超过50，即最多保留50%的空间，但是保留过多会导致新生代可用空间少，过少可能会增加新生代晋升失败，那将会导致更为复杂的串行回收。
- G1NewSizePercent是一个实验参数，需要使用-XX:+UnlockExperimentalVMOptions才能改变选项。有实验表明G1在回收Eden分区的时候，大概每GB需要100ms，所以可以根据停顿时间，相应地调整。这个值在内存比较大的时候需要减少，例如32G可以设置-XX:G1NewSizePercent = 3，这样Eden至少保留大约1GB的空间，从而保证收集效率。
- 参数MaxGCPauseMillis指期望停顿时间，可根据系统配置和业务动态调整。因为G1在垃圾收集的时候一定会收集新生代，所以需要配合新生代大小的设置来确定，如果该值太小，连新生代都不能收集完成，则没有任何意义，每次除了新生代之外只能多收集一个额外老生代分区。
- 参数G1ConfidencePercent指GC预测置信度，该值越小说明基于过去历史数据的预测越准确，例如设置为0则表示收集的分区基本和过去的衰减均值相关，无波动，所以可以根据过去的衰减均值直接预测下一次预测的时间。反之该值越大，说明波动越大，越不准确，需要加上衰减方差来补偿。

# 数据库性能瓶颈优化

数据库出现性能瓶颈，对外表现有几个方面：
- 大量请求阻塞：在高并发场景下，大量请求都需要操作数据库，导致连接数不够了，请求处于阻塞状态。
- SQL操作变慢：如果数据库中存在一张上亿数据量的表，一条SQL没有命中索引会全表扫描，这个查询耗时会非常久。
- 存储出现问题：业务量剧增，单库数据量越来越大，给存储造成巨大压力。

数据库处理性能瓶颈的方法：
- 软件层面：SQL调优、表结构优化、架构优化、分库分表
    - SQL调优
        - 主要目的是尽可能的让那些慢SQL变快，让SQL执行尽量命中索引。
        - 在MySQL配置文件中配置几个参数即可开启慢SQL记录。
        - 通过`explain`这个命令来查看SQL语句的执行计划，通过观察执行结果很容易就知道该SQL语句是不是全表扫描、有没有命中索引。<br>返回有一列叫`type`，常见取值从左到右，性能从差到好：`ALL`、`index`、`range`、 `ref`、`eq_ref`、`const`、`system`、`NULL`。
    - 表结构优化
        - 例如，设置数据库表冗余字段，要尽量选择不经常更新的字段，因为可能涉及一致性问题。
    - 架构优化
        - 当单台数据库实例扛不住，可以增加实例组成集群对外服务。
        - 当发现读请求明显多于写请求（读多写少）时，我们可以让读写分离，主实例负责写，从实例对外提供读的能力。
        - 如果读实例压力依然很大，可以在数据库前面加入缓存如Redis，让请求优先从缓存取数据减少数据库访问，只是需要注意数据一致性问题。
    - 分库分表
        - 分库
            - 单数据库的能够支撑的并发量是有限的，拆成多个库可以使服务间不用竞争，提升服务的性能。
        - 分表
            - 水平切分和垂直切分
            - 单库内分表和多库内分表
        - 带来的复杂性
            - 跨库关联查询
            - 分布式事务
            - 排序、分页、函数计算问题
            - 分布式ID
            - 多数据源
- 硬件层面：增加数据库服务器性能
    - CPU、内存、磁盘、网络等都是重要的计算资源。
    - 在前期业务量比较小的时候，升级硬件数据库性能可以得到较大提升；但是在后期，升级硬件得到的收益就不那么明显了。

# 工程编译效率优化

工程编译效率低的原因：
- 代码扫描耦合在编译中，整体时间过长，占比比较高。
- 依赖复杂，无用依赖多。
- Root POM依赖管理机制导致依赖更新频繁，依赖出错时影响范围广。
- 包依赖未缓存，需要重复拉取。
- 个别未改造的SNAPSHOT依赖影响效率。
- 对易改变的实现依赖(component/recommend)造成的一系列问题。
- 编译错误不友好，理解困难(lint)/上游breaking change导致的错误不好回溯。

优化编译效率的方法：
- 优化不合理的依赖以及依赖排除。
- 将代码检查插件并行化。
- 编译脚本优化。
- Java依赖缓存优化。
