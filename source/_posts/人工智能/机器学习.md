---
title: 机器学习
date: 2020-09-26 19:16:21
summary: 本文分享机器学习的相关内容。
tags:
- 机器学习
- 人工智能
categories:
- 人工智能
---

# 机器学习常用术语

- **观察值**（*observation*）：我们观察到的单个单位——例如，一个人、一次销售或一条记录。
- **学习算法**（*learning algorithm*）：用来学习模型的最佳参数的算法——例如，线性回归、朴素贝叶斯或决策树。
- **模型**（*model*）：学习算法的输出。学习算法训练出来的模型可以用来做预测。
- **参数**（*parameter*）：一个模型在训练过程中学到的权重或系数。
- **超参数**（*hyperparameter*）：一个学习算法在训练前需要设置的一组参数。
- **性能**（*performance*）：用来评估模型的指标。
- **损失**（*loss*）：一个需要在训练中最小化或最大化的指标。
- **训练**（*train*）：使用类似梯度下降之类的数学方法将一个学习算法应用到数据上。
- **拟合**（*fit*）：使用分析方法将一个机器学习算法应用到数据上。
- **数据**（*data*）：一组观察值。

更多术语：[轻戳这里](https://developers.google.cn/machine-learning/glossary?hl=zh-cn)

# 机器学习处理不均衡分类

在真实的场景中，不均衡的分类到处可见，比如大多数访客都不会单击“购买”按钮，大多数用户都不会付费成为“VIP”，有些癌症或遗传病也是十分罕见的。因此，处理不均衡分类就称为机器学习的一个常见任务。

对此，最好的解决方案是收集更多的观观察值——尤其是占少数的分类的观察值。可惜的是，这可能很难做到，所以我们需要求助于其他手段。

次优的解决方案是选择更适用于评估不均衡数据的标准。准确率常常被作为评估模型性能的标准，但用准确率来评估不均衡分类是不合适的。例如，如果样本中只有0.5%的人得了某种罕见的癌症，那么即使我们的模型预测没有人会得这种癌症，准确率也只能达到99.5%。很明显，这也不是我们想要的。一些更有效的评估标准，如混淆矩阵、精确度、召回率、F1值以及ROC曲线都是值得学习的。

第三个解决方案是在一些分类器模型中使用分类权重参数，这样就能针对不均衡的分类来调整算法。scikit-learn的很多分类器都有class_weight参数，便于使用。

第四个方案和第五个方案是相关的：下采样和上采样。在下采样中，需要从占多数的分类中创建一个子集，其观察之数量与占少数的分类的观察值数量相等。在上采样中，采用有放回的方式对占少数的分类重复采样，一次创建与占多数的分类有相同数量观察值的数据集。到底是下采样还是上采样，需要根据实际场景做决定。通常情况下，应该同时尝试两种方法，看看哪种效果更好。

# 机器学习中的缺失值及其填充处理

大多数机器学习算法不允许目标值或特征数组中存在缺失值。因此，不能简单的忽略数据中的缺失值，而是要在数据预处理阶段解决这个问题。

最简单的解决方法是删除所有含其缺失值的观察值，用Numpy或Pandas很容易实现。

即便如此，删除带缺失值的观察值也是一件令人心痛的决定，因为这样做会让算法丢失那些观察值中那些非缺失值的信息，所以删除观察值只能作为最终别无他法时不得已的选择。

还有一点很重要，删除观察值可能会在数据中引入偏差，这主要由缺失值的成因决定。

缺失值一共有三种类型：
- 完全随机缺失（MCAR）
数据缺失的可能性与任何其他东西无关。
例如，某个接受问卷调查的人会在回答问题前先掷一个骰子，如果掷出了6，那她就跳过那个问题不做回答。
- 随机缺失（MAR）
数据缺失的可能性不是完全随机的，与已经存在的其他特征有关。
例如，在一次问卷调查中会问及性别和薪资水平，那么接受调查的女性更可能会跳过薪资的问题，但她们选择是否作答要看我们是否已经得知其性别信息。
- 完全非随机缺失（MNAR）
数据缺失的可能性完全是非随机的，并且与未在特征中反映出的信息有关。
例如，一个问卷调查中会问及薪资水平，那么接受问卷调查的女性更可能会跳过薪资的问题，但是我们的数据中没有关于性别的特征。

如果观察值是MCAR或者MAR，那么有时候删除它们是可以接受的。
如果它们是MNAR，那么数据缺失本身其实就是一个信息。删除MNAR观察值会导致数据产生偏差，因为这些观察值是由未观察到的系统效应产生的。

接下来说说缺失值的填充处理策略，主要有两种，各有利弊。

首先，可以使用机器学习来预测缺失值。为了达到目的，可以将带有缺失值的特征当作一个目标向量，然后使用剩余的特征来预测缺失值。虽然可以使用各种机器学习算法来做预测，但是流行的选择是KNN，作为一种机器学习算法，KNN使用k个最临近的观察值（根据某种距离度量算法计算得到）来预测缺失值。KNN的不足是，为了知道哪些观察值距离缺失值最近，需要计算每一个观察值与缺失值之间的距离。对于小数据集，这样处理没有问题，但是如果数据集中有成千上万的观察值，计算量将成为一个很严重的问题。

一个比较容易扩展到大数据集的方案是使用平均值来代替缺失值。尽管这样做的效果没有使用KNN来得好，但是“平均值填充策略”很容易扩展到包含成千上万观察值的大数据集。

最后说一下，如果要采用填充策略，最好是创建一个二元特征来表明该观察值是否包含填充值。

# 机器学习中的异常值的识别和处理

用于机器学习的数据难免有异常值的存在，这就需要我们识别并处理异常值。

可惜，并没有一个通用的识别异常值的解决方案，每种方法都有自己的优势和不足，尝试综合使用多种技术（如基于EllipticEnvelope和基于IQR的识别）并从整体上来看结果。

对于被判定为异常值的数据，我们不妨也关注一下。比如我们的数据集是一个关于房子的数据集，其中一个特征是房间数。此时，如果一个房子因为拥有100+个房间被判定为异常值，那我们可以问问自己：这个数据真的是异常数据，还是它本质是一个旅馆呢？

再说说处理异常值，它和识别异常值一样，没有什么绝对的准则。我们可以从两个角度（方面）来考虑对异常值的处理：
第一，要弄清楚是什么让它们成为异常值的。如果你认为它们是错误的观察值，比如他们来自一个坏掉的传感器或者是被记错了的值，那么就要丢弃他们或者使用NaN来替换异常值，因为这些数据无法被我们信任。但是，如果我们认为这些异常值时极端值（比如一个超级豪宅有100间卧室），那么把它们标记为异常值或者对它们的值进行转换是比较合适的。
第二，应该基于机器学习的目标来处理异常值。例如，如果想要基于房屋的特征来预测其价格，那么可以合理的假设有100间卧室的大宅子的价格是由不同于普通家庭住宅的特征驱动的。此外，如果使用一个在线住房贷款的Web应用的部分数据来训练一个模型，那么就要假设潜在用户中不存在想要买一栋有几百间卧室的豪宅的亿万富翁。

所以，处理异常值，首先要想想为什么这个（些）数据是异常值，然后对于数据要有一个最终的目标。最重要的是，要记住“决定不处理异常值”本身就是一个有潜在影响的决定。（想想Java的异常处理吧，发现异常全都不处理的话要异常处理体系干嘛呢？）

另外，如果数据中有异常值，那么采用标准化方法做缩放就不太合适了，因为平均值和方差受异常值的影响很大。这种情况下，需要针对异常值使用一个鲁棒性更高的缩放方法，比如RobustScaler。
